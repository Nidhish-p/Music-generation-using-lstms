# MIDI-based AI Melody Generation for Expressive Music Synthesis ğŸµğŸ¤–

This project automates **melody generation using deep learning**.  
It learns musical patterns from MIDI files and generates new monophonic melodies â€” enabling users to **create and listen to AI-composed music**.

ğŸš€ Built as part of a **machine learning project on sequence modeling and generative AI**.  
Achieved **78% accuracy** in monophonic melody synthesis using a two-layer LSTM model.


## ğŸ“Œ Problem Statement
Manual music composition is time-consuming and requires musical expertise.  
This project aims to **automate melody creation** by:
- Learning musical structure from MIDI data
- Generating coherent and expressive melodies
- Providing an interactive platform for AI-generated music


## ğŸ”§ Key Highlights
- âœ… **MIDI dataset preprocessing** â†’ Parsed, cleaned, and encoded MIDI files
- âœ… **Two-layer LSTM model** â†’ Captured temporal dependencies in melodies
- âœ… **Temperature-based sampling** â†’ Controlled creativity during generation
- âœ… **Hyperparameter tuning** â†’ Improved stability and melody consistency
- âœ… **End-to-end system** â†’ Model integrated with a Django web interface


## ğŸ› ï¸ Tech Stack
- **Python**
- **Deep Learning (LSTM)**
- **MIDI Processing**
- **TensorFlow / Keras**
- **Django**
- **HTML / CSS**


## ğŸ“Š Results
- Achieved **78% accuracy** in monophonic melody synthesis
- Generated musically coherent MIDI sequences
- Enabled real-time melody generation and playback via web interface


## ğŸµ Demo
<img src="demo.png" width="500">


## ğŸš€ How to Run
```bash
# Clone repository
git clone https://github.com/yourusername/AI-Music-Generation-LSTM.git
cd AI-Music-Generation-LSTM

# Install requirements
pip install -r requirements.txt

# Train the model (optional)
python train.py

# Run Django application
python manage.py runserver
